<!DOCTYPE HTML>
<html lang="en">
  <head>
    <meta http-equiv="Content-Type" content="text/html; charset=UTF-8">

    <title>Zenan Shi</title>

    <meta name="author" content="Zenan Shi">
    <meta name="viewport" content="width=device-width, initial-scale=1">
    <link rel="shortcut icon" href="images/favicon/favicon.ico" type="image/x-icon">
    <link rel="stylesheet" type="text/css" href="stylesheet.css">
    
  </head>

  <body>
    <table style="width:100%;max-width:800px;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
      <tr style="padding:0px">
        <td style="padding:0px">
          <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
            <tr style="padding:0px">
              <td style="padding:2.5%;width:63%;vertical-align:middle">
                <p class="name" style="text-align: center;">
                  Zenan Shi
                </p>
                <p>I am currently a postdoctoral researcher at the College of Computer Science and Technology at Jilin University, where I work closely with <a href="https://ccst.jlu.edu.cn/info/1367/19063.htm">Prof. Haipeng Chen</a> and <a href="https://dongzhang89.github.io/">Prof. Dong Zhang</a>.
                </p>
                <p>
                Before that, I earned my Ph.D. degree in Computer Science and Technology from Jilin University, where I was supervised by Prof. Xuanjing Shen. From Aug. 2019 to Aug. 2020, I was supported by the China Scholarship Council as a joint Ph.D. student at <a href="https://mreallab.github.io/">MReaL Lab</a> of Nanyang Technological University (NTU), supervised by <a href="https://personal.ntu.edu.sg/hanwangzhang/">Prof. Zhang Hanwang</a>.
                </p>
		<p>
		I'm interested in deepfake detection, computer vision, and medical image analysis. 
		</p>
		<p>
		â¤ï¸Do good deeds, and don't worry about the future.â¤ï¸ 
		</p>      
                <p style="text-align:center">
                  <a href="mailto:shizn@jlu.edu.cn">Email</a> &nbsp;/&nbsp;
                  <a href="https://scholar.google.com/citations?user=8KJE6zEAAAAJ&hl=zh-CN&oi=ao">Scholar</a> &nbsp;/&nbsp;
                  <a href="https://github.com/Zenanshi92">Github1</a> &nbsp;/&nbsp;
		  <a href="https://github.com/znshi">Github2</a> &nbsp;/&nbsp;
		  <a href="https://orcid.org/0000-0001-8554-4127">ORCID</a>
                </p>
		      
              </td>
              <td style="padding:2.5%;width:40%;max-width:40%">
		<img src="profile2.jpg" width="210">  
                <p align="center" class="view"><font color="black">Machine Learning and Visual Reasoning Lab<br>Office: ç‹æ¹˜æµ©æ¥¼B126<br>shizn@jlu.edu.cn</font></p>
              </td>
            </tr>

        </tbody></table>
          <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
              <tr>
              <td style="padding:5px;width:100%;vertical-align:middle">
                <h2>News</h2>
                <p>
                  <li><em><strong><font color="#a82e2e">Just a few months left until the end of my postdoctoral position. Good luck!</font></strong></em> <br></li> 
		  <li> <strongsmall>[2023/08]</strongsmall> &nbsp;&nbsp;<smalll>1 paper is accepted by IJCAI 2023.</smalll><br/>	
                </p>
              </td>
            </tr>
          </tbody></table>
          <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>

	</tbody></table>
          <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
              <tr>
              <td style="padding:5px;width:100%;vertical-align:middle">
                <h2>Publication <a href="https://scholar.google.com/citations?user=8KJE6zEAAAAJ&hl=zh-CN&oi=ao" style="font-size:22px;">[Google Scholar]</a></h2>
	      </td>
            </tr>
          </tbody></table>
          <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>

<p>* denotes co-first authors.<br />
# denotes corresponding author.</p>		  
<h4 id="-2024">ğŸ’ª 2024 ğŸ€:</h4>
<ul>
  <li>
  </li>	 	 
</ul>	  
<h4 id="-2023">ğŸ’ª 2023 ğŸ€:</h4>		  
 <ul>
  <li>
    <div onmouseout="bog_stop()" onmouseover="bog_start()" style="padding:10px;width:75%;vertical-align:middle">
      <span class="papertitle">Discrepancy-Guided Reconstruction Learning for Image Forgery Detection</span>
      <br>
      <strong>Zenan Shi</strong>,
      <a href="">Haipeng Chen</a>,
      <a href="https://scholar.google.com/citations?hl=zh-CN&user=-gtmMpIAAAAJ">Long Chen</a>,
      <a href="">Dong Zhang</a>#
      <br>
      <em>International Joint Conference on Artificial Intelligence, <strong>IJCAI 2023</strong></em>
      <br>
      <a href="https://www.ijcai.org/proceedings/2023/0154.pdf">[Paperlink]</a>, 
      /
      <a href="https://github.com/znshi/DisGRL">[Code]<a>
    </div>
  </li>
  <li>
    <div onmouseout="bog_stop()" onmouseover="bog_start()" style="padding:10px;width:75%;vertical-align:middle">
      <span class="papertitle">Transformer-auxiliary neural networks for image manipulation localization by operator inductions</span>
      <br>
      <strong>Zenan Shi</strong>,
      <a href="">Haipeng Chen</a>,
      <a href="">Dong Zhang</a>#
      <br>
      <em>IEEE Transactions on Circuits and Systems for Video Technology, <strong>TCSVT 2023</strong></em>
      <br>
      <a href="https://ieeexplore.ieee.org/abstract/document/10057470">[Paperlink]</a>
    </div>
  </li>	
  <li>
    <div onmouseout="bog_stop()" onmouseover="bog_start()" style="padding:10px;width:75%;vertical-align:middle">
      <span class="papertitle">PL-GNet: Pixel Level Global Network for detection and localization of image forgeries</span>
      <br>
      <strong>Zenan Shi</strong>,
      <a href="">Xuanjing Shen</a>,	    
      <a href="">Haipeng Chen</a>#,
      <a href="">Yingda Lyu</a>
      <br>
      <em>Signal Processing: Image Communication, <strong>SPIC 2023</strong></em>
      <br>
      <a href="https://www.sciencedirect.com/science/article/abs/pii/S092359652300111X">[Paperlink]</a>, 
      /
      <a href="https://github.com/znshi/PL-GNet">[Code]</a>
    </div>
  </li>	
  <li>
    <div onmouseout="bog_stop()" onmouseover="bog_start()" style="padding:10px;width:75%;vertical-align:middle">
      <span class="papertitle">Pretraining-Driven Multimodal Boundary Aware Vision Transformer</span>
      <br>
      <strong>Zenan Shi</strong>,
      <a href="">Haipeng Chen</a>#,
      <a href="">Dong Zhang</a>,	    
      <a href="">Xuanjing Shen</a>	    
      <br>
      <em>Journal of Software (in Chinese), <strong>è½¯ä»¶å­¦æŠ¥ 2023</strong></em>
      <br>
      <a href="https://www.jos.org.cn/josen/article/abstract/6768">[Paperlink]</a>
    </div>
  </li>			 
</ul>
<h4 id="-2022">ğŸ’ª 2022 ğŸ€:</h4>
<ul>
  <li>
  </li>	 	 
</ul>	
<h4 id="-2021">ğŸ’ª 2021 ğŸ€:</h4>
<ul>
  <li>
  </li>	 	 
</ul>    
<h4 id="-2020-">ğŸ’ª 2020- ğŸ€:</h4>
<ul>
  <li>
  </li>	 	 
</ul>	          
     
        </tbody></table>
          <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
              <tr>
              <td style="padding:5px;width:100%;vertical-align:middle">
                <h2>FundingsğŸ‰ </h2>
                <p>
                  <li>Youth Interdisciplinary Program of Jilin University <br></li> 	
                </p>
              </td>
            </tr>
          </tbody></table>
          <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>

	  </tbody></table>
          <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
              <tr>
              <td style="padding:5px;width:100%;vertical-align:middle">
                <h2>professional-services-reviewers ğŸŒ»</h2>
                <p>
                  <li>IEEE Transactions on Circuits and Systems for Video Technolog</li>
                  <li>Neurocomputing, Neural Networks, Pattern Recognition</li>	
		  <li>ACM International Conference on Multimedia, 2024-2024</li>
                </p>
              </td>
            </tr>
          </tbody></table>
          <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
		  
		
          </tbody></table>
          <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
            <tr>
              <td style="padding:0px">
                <br>
                <p style="text-align:right;font-size:small;">
                  This awesome template borrowed from <a href="https://github.com/jonbarron/jonbarron_website">Jon Barron</a>~
                </p>
              </td>
            </tr>
          </tbody></table>
        </td>
      </tr>
    </table>
  </body>
</html>
