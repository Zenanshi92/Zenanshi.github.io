<!DOCTYPE HTML>
<html lang="en">
  <head>
    <meta http-equiv="Content-Type" content="text/html; charset=UTF-8">

    <title>Zenan Shi</title>

    <meta name="author" content="Zenan Shi">
    <meta name="viewport" content="width=device-width, initial-scale=1">
    <link rel="shortcut icon" href="images/favicon/favicon.ico" type="image/x-icon">
    <link rel="stylesheet" type="text/css" href="stylesheet.css">
    
  </head>

  <body>
    <table style="width:100%;max-width:800px;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
      <tr style="padding:0px">
        <td style="padding:0px">
          <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
            <tr style="padding:0px">
              <td style="padding:2.5%;width:63%;vertical-align:middle">
                <p class="name" style="text-align: center;">
                  Zenan Shi
                </p>
                <p>I am currently a postdoctoral researcher at the College of Computer Science and Technology at Jilin University, where I work closely with <a href="https://ccst.jlu.edu.cn/info/1367/19063.htm">Prof. Haipeng Chen</a> and <a href="https://dongzhang89.github.io/">Prof. Dong Zhang</a>.
                </p>
                <p>
                Before that, I earned my Ph.D. degree in Computer Science and Technology from Jilin University, where I was supervised by Prof. Xuanjing Shen. From Aug. 2019 to Aug. 2020, I was supported by the China Scholarship Council as a joint Ph.D. student at <a href="https://mreallab.github.io/">MReaL Lab</a> of Nanyang Technological University (NTU), supervised by <a href="https://personal.ntu.edu.sg/hanwangzhang/">Prof. Zhang Hanwang</a>.
                </p>
		<p>
		I'm interested in deepfake detection, computer vision, and medical image analysis. 
		</p>
		<p>
		â¤ï¸Do good deeds, and don't worry about the future.â¤ï¸ 
		</p>      
                <p style="text-align:center">
                  <a href="mailto:shizn@jlu.edu.cn">Email</a> &nbsp;/&nbsp;
                  <a href="https://scholar.google.com/citations?user=8KJE6zEAAAAJ&hl=zh-CN&oi=ao">Scholar</a> &nbsp;/&nbsp;
                  <a href="https://github.com/Zenanshi92">Github1</a> &nbsp;/&nbsp;
		  <a href="https://github.com/znshi">Github2</a> &nbsp;/&nbsp;
		  <a href="https://orcid.org/0000-0001-8554-4127">ORCID</a>
                </p>
		      
              </td>
              <td style="padding:2.5%;width:40%;max-width:40%">
		<img src="profile2.jpg" width="210">  
                <p align="center" class="view"><font color="black">Machine Learning and Visual Reasoning Lab<br>Office: ç‹æ¹˜æµ©æ¥¼B126<br>shizn@jlu.edu.cn</font></p>
              </td>
            </tr>

        </tbody></table>
          <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
              <tr>
              <td style="padding:5px;width:100%;vertical-align:middle">
                <h2>News</h2>
                <p>
                  <li><em><strong><font color="#a82e2e">Just a few months left until the end of my postdoctoral position. Good luck!</font></strong></em> <br></li> 
		  <li> <strongsmall>[2023/04/19]</strongsmall> &nbsp;&nbsp;<smalll>1 paper is accepted by IJCAI 2023.</smalll><br/>
		  <li> <strongsmall>[2024/07/25]</strongsmall> &nbsp;&nbsp;<smalll>1 paper is accepted by TOMM 2024.</smalll><br/>
                </p>
              </td>
            </tr>
          </tbody></table>
          <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>

	</tbody></table>
          <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
              <tr>
              <td style="padding:5px;width:100%;vertical-align:middle">
                <h2>Publication <a href="https://scholar.google.com/citations?user=8KJE6zEAAAAJ&hl=zh-CN&oi=ao" style="font-size:22px;">[Google Scholar]</a></h2>
	      </td>
            </tr>
          </tbody></table>
          <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>

<p>* denotes co-first authors.<br />
# denotes corresponding author.</p>		  
<h4 id="-2024">ğŸ’ª 2024 ğŸ€:</h4>
<ul>
  <li>
    <div onmouseout="bog_stop()" onmouseover="bog_start()" style="padding:10px;width:75%;vertical-align:middle">
      <span class="papertitle">Customized Transformer Adapter with Masked Frequency Modeling for Deepfake Detection</span>
      <br>
      <strong>Zenan Shi</strong>,
      <a href="">Haipeng Chen</a>,
      <a href="">Yixin Jia</a>,
      <a href="">Dong Zhang</a>#	    
      <br>
      <em>IEEE Transactions on Information Forensics and Security, <strong>TIFS 2024 (submitted) (CCF-A)</strong></em>
      <br>
      <a href="https://www.ijcai.org/proceedings/2023/0154.pdf">[Paperlink]</a>, 
      <a href="https://github.com/znshi/DisGRL">[Code]</a>
    </div>
  </li>	 
  <li>
    <div onmouseout="bog_stop()" onmouseover="bog_start()" style="padding:10px;width:75%;vertical-align:middle">
      <span class="papertitle">Robustifying Vision Transformer for Image Forgery Localization with Multi-Exit Architectures
Pattern Recognition</span>
      <br>
      <strong>Zenan Shi</strong>,
      <a href="">Haipeng Chen</a>,
      <a href="">Dong Zhang</a>#
      <br>
      <em>Pattern Recognition, <strong>PR (under review) (CCF-B, ä¸­ç§‘é™¢1åŒº)</strong></em>
      <br>
      <a href="https://www.ijcai.org/proceedings/2023/0154.pdf">[Paperlink]</a>
    </div>
  </li>
  <li>
    <div onmouseout="bog_stop()" onmouseover="bog_start()" style="padding:10px;width:75%;vertical-align:middle">
      <span class="papertitle">Face Reconstruction-Based Generalized Deepfake Detection Model with Residual Outlook Attention</span>
      <br>
      <strong>Zenan Shi</strong>,
      <a href="">Wenyu Liu</a>#,
      <a href="">Haipeng Chen</a>
      <br>
      <em>ACM Transactions on Multimedia Computing, Communications, and Applications, <strong>TOMM 2024(CCF-B, ä¸­ç§‘é™¢3åŒº)</strong></em>
      <br>
      <a href="https://www.ijcai.org/proceedings/2023/0154.pdf">[Paperlink]</a>
    </div>
  </li>	
</ul>	  
<h4 id="-2023">ğŸ’ª 2023 ğŸ€:</h4>		  
 <ul>
  <li>
    <div onmouseout="bog_stop()" onmouseover="bog_start()" style="padding:10px;width:75%;vertical-align:middle">
      <span class="papertitle">Discrepancy-Guided Reconstruction Learning for Image Forgery Detection</span>
      <br>
      <strong>Zenan Shi</strong>,
      <a href="">Haipeng Chen</a>,
      <a href="https://scholar.google.com/citations?hl=zh-CN&user=-gtmMpIAAAAJ">Long Chen</a>,
      <a href="">Dong Zhang</a>#
      <br>
      <em>International Joint Conference on Artificial Intelligence, <strong>IJCAI 2023 (CCF-A)</strong></em>
      <br>
      <a href="https://www.ijcai.org/proceedings/2023/0154.pdf">[Paperlink]</a>, 
      <a href="https://github.com/znshi/DisGRL">[Code]</a>
    </div>
  </li>
  <li>
    <div onmouseout="bog_stop()" onmouseover="bog_start()" style="padding:10px;width:75%;vertical-align:middle">
      <span class="papertitle">Transformer-auxiliary neural networks for image manipulation localization by operator inductions</span>
      <br>
      <strong>Zenan Shi</strong>,
      <a href="">Haipeng Chen</a>,
      <a href="">Dong Zhang</a>#
      <br>
      <em>IEEE Transactions on Circuits and Systems for Video Technology, <strong>TCSVT 2023 (CCF-B, ä¸­ç§‘é™¢1åŒº)</strong></em>
      <br>
      <a href="https://ieeexplore.ieee.org/abstract/document/10057470">[Paperlink]</a>
    </div>
  </li>	
  <li>
    <div onmouseout="bog_stop()" onmouseover="bog_start()" style="padding:10px;width:75%;vertical-align:middle">
      <span class="papertitle">PL-GNet: Pixel Level Global Network for detection and localization of image forgeries</span>
      <br>
      <strong>Zenan Shi</strong>,
      <a href="">Xuanjing Shen</a>,	    
      <a href="">Haipeng Chen</a>#,
      <a href="">Yingda Lyu</a>
      <br>
      <em>Signal Processing: Image Communication, <strong>SPIC 2023 (CCF-C, ä¸­ç§‘é™¢3åŒº)</strong></em>
      <br>
      <a href="https://www.sciencedirect.com/science/article/abs/pii/S092359652300111X">[Paperlink]</a>, 
      <a href="https://github.com/znshi/PL-GNet">[Code]</a>
    </div>
  </li>	
  <li>
    <div onmouseout="bog_stop()" onmouseover="bog_start()" style="padding:10px;width:75%;vertical-align:middle">
      <span class="papertitle">Pretraining-Driven Multimodal Boundary Aware Vision Transformer</span>
      <br>
      <strong>Zenan Shi</strong>,
      <a href="">Haipeng Chen</a>#,
      <a href="">Dong Zhang</a>,	    
      <a href="">Xuanjing Shen</a>	    
      <br>
      <em>Journal of Software (in Chinese), <strong>è½¯ä»¶å­¦æŠ¥ 2023 (CCFè®¡ç®—é¢†åŸŸé«˜è´¨é‡ç§‘æŠ€æœŸåˆŠT1 ç±»æœŸåˆŠ)</strong></em>
      <br>
      <a href="https://www.jos.org.cn/josen/article/abstract/6768">[Paperlink]</a>
    </div>
  </li>
  <li>
    <div onmouseout="bog_stop()" onmouseover="bog_start()" style="padding:10px;width:75%;vertical-align:middle">
      <span class="papertitle">Semantic-Agnostic Progressive Subtractive Network for Image Manipulation Detection and Localization</span>
      <br>
      <a href="">Dengyun Xu</a>,
      <a href="">Xuanjing Shen</a>,	    
      <strong>Zenan Shi</strong>#,
      <a href="">Na Ta</a>,	    
      <br>
      <em>Neurocomputing, <strong>2023 (CCF-C, ä¸­ç§‘é™¢2åŒº)</strong></em>
      <br>
      <a href="https://www.sciencedirect.com/science/article/abs/pii/S0925231223003867">[Paperlink]</a>
    </div>
  </li>			 
	 
</ul>
<h4 id="-2022">ğŸ’ª 2022 ğŸ€:</h4>
<ul>
  <li>
    <div onmouseout="bog_stop()" onmouseover="bog_start()" style="padding:10px;width:75%;vertical-align:middle">
      <span class="papertitle">PR-NET: Progressively-refined neural network for image manipulation localization</span>
      <br>
      <strong>Zenan Shi</strong>,
      <a href="">Chaoqun Chang</a>,	    
      <a href="">Haipeng Chen</a>#,
      <a href="">Xiaoyu Du</a>,	    
      <a href="">Hanwang Zhang</a>	    
      <br>
      <em>International Journal of Intelligent Systems, <strong>2022 (ä¸­ç§‘é™¢2åŒº)</strong></em>
      <br>
      <a href="https://onlinelibrary.wiley.com/doi/abs/10.1002/int.22822">[Paperlink]</a>
    </div>
  </li>	
  <li>
    <div onmouseout="bog_stop()" onmouseover="bog_start()" style="padding:10px;width:75%;vertical-align:middle">
      <span class="papertitle">RB-Net: integrating region and boundary features for image manipulation localization</span>
      <br>
      <a href="">Dengyun Xu</a>,	    
      <a href="">Xuanjing Shen</a>,
      <a href="">Yongping Huang</a>,	    
      <strong>Zenan Shi</strong>#
      <br>
      <em>Multimedia System, <strong>2022 (CCF-C, ä¸­ç§‘é™¢3åŒº)</strong></em>
      <br>
      <a href="https://link.springer.com/article/10.1007/s00530-022-00903-z">[Paperlink]</a>
    </div>
  </li>
  <li>
    <div onmouseout="bog_stop()" onmouseover="bog_start()" style="padding:10px;width:75%;vertical-align:middle">
      <span class="papertitle">FPF-Net: Feature Propagation and Fusion based on Attention Mechanism for Pancreas Segmentation</span>
      <br>
      <a href="">Haipeng Chen</a>,	    
      <a href="">Yunjie Liu</a>,
      <strong>Zenan Shi</strong>#
      <br>
      <em>Multimedia System, <strong>2022 (CCF-C, ä¸­ç§‘é™¢3åŒº)</strong></em>
      <br>
      <a href="https://link.springer.com/article/10.1007/s00530-022-00963-1">[Paperlink]</a>
    </div>
  </li>	
  <li>
    <div onmouseout="bog_stop()" onmouseover="bog_start()" style="padding:10px;width:75%;vertical-align:middle">
      <span class="papertitle">Adaptive Multi-order Graph Neural Networks for Human Motion Prediction</span>
      <br>
      <a href="">Pengxiang Su</a>,	    
      <a href="">Xuanjing Shen</a>,
      <strong>Zenan Shi</strong>#
      <br>
      <em>IEEE International Conference on Multimedia and Expo, <strong>ICME, 2022 (CCF-B)</strong></em>
      <br>
      <a href="https://ieeexplore.ieee.org/abstract/document/9859980">[Paperlink]</a>
    </div>
  </li>	
</ul>	
<h4 id="-2020-">ğŸ’ª 2020- ğŸ€:</h4>
<ul>
  <li>
    <div onmouseout="bog_stop()" onmouseover="bog_start()" style="padding:10px;width:75%;vertical-align:middle">
      <span class="papertitle">Global semantic consistency network for image manipulation detection</span>
      <br>
      <strong>Zenan Shi</strong>,
      <a href="">Xuanjing Shen</a>,	    
      <a href="">Haipeng Chen</a>#,
      <a href="">Yingda Lyu</a>	       
      <br>
      <em>IEEE Signal Processing Letters, <strong>SPL, 2020 (CCF-C, ä¸­ç§‘é™¢3åŒº)</strong></em>
      <br>
      <a href="https://ieeexplore.ieee.org/abstract/document/9206061">[Paperlink]</a>
    </div>
    <li>
    <div onmouseout="bog_stop()" onmouseover="bog_start()" style="padding:10px;width:75%;vertical-align:middle">
      <span class="papertitle">Splicing image forgery detection using textural features based on the grey level co-occurrence matrices</span>
      <br>
      <a href="">Xuanjing Shen</a>,
      <strong>Zenan Shi</strong>,	    
      <a href="">Haipeng Chen</a># 
      <br>
      <em>IET Image Processing, <strong>2017 (CCF-C, ä¸­ç§‘é™¢4åŒº)</strong></em>
      <br>
      <a href="https://ietresearch.onlinelibrary.wiley.com/doi/full/10.1049/iet-ipr.2016.0238">[Paperlink]</a>
    </div>	  
  </li>			 	 
</ul>              
     
        </tbody></table>
          <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
              <tr>
              <td style="padding:5px;width:100%;vertical-align:middle">
                <h2>FundingsğŸ‰ </h2>
                <p>
                  <li>Youth Interdisciplinary Program of Jilin University <br></li> 	
                </p>
              </td>
            </tr>
          </tbody></table>
          <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>

	  </tbody></table>
          <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
              <tr>
              <td style="padding:5px;width:100%;vertical-align:middle">
                <h2>professional-services-reviewers ğŸŒ»</h2>
                <p>
                  <li>IEEE Transactions on Circuits and Systems for Video Technolog</li>
                  <li>Knowledge-Based Systems, Neurocomputing, Neural Networks, Pattern Recognition</li>	
		  <li>ACM International Conference on Multimedia, 2024-2024</li>
                </p>
              </td>
            </tr>
          </tbody></table>
          <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
		  
		
          </tbody></table>
          <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
            <tr>
              <td style="padding:0px">
                <br>
                <p style="text-align:right;font-size:small;">
                  This awesome template borrowed from <a href="https://github.com/jonbarron/jonbarron_website">Jon Barron</a>~
                </p>
              </td>
            </tr>
          </tbody></table>
        </td>
      </tr>
    </table>
  </body>
</html>
